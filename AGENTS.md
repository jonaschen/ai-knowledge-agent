# AI Software Studio Constitution (v2.3)

## 1. Core Philosophy: Evidentialism & Automation

**Objective:** Build a self-evolving "Deep Context Reader" system.

**Principle 1:** Evidentialism. No hallucinations. All claims must be backed by Researcher findings.

**Principle 2:** Automation. The studio/ layer manages the product/ layer.

**Principle 3:** TDD. Red-Green-Refactor is mandatory for all code changes.

**Principle 4:** Refactor according to the SOLID principles.
 

---

## 2. Official Directory Structure (The Territory)

All agents MUST respect this structure. DO NOT delete files listed here unless explicitly instructed.

```text
/
â”œâ”€â”€ product/                <-- [Production Line] The core content generation system
â”‚   â”œâ”€â”€ main.py             # Entry point & Orchestrator
â”‚   â”œâ”€â”€ curator.py          # Book Selection & Reliability Filter (Fallback: Tavily)
â”‚   â”œâ”€â”€ researcher.py       # [The Eyes] Web Search & Evidence Gathering (Tavily API)
â”‚   â”œâ”€â”€ analyst_core.py     # [The Brain] Deep Thematic Analysis (Recursive Tree)
â”‚   â””â”€â”€ broadcaster.py      # [The Voice] TTS Generation (Chirp 3)
â”‚
â”œâ”€â”€ studio/                 <-- [Management Layer] Tools that build the product
â”‚   â”œâ”€â”€ architect.py        # [Tech Lead] Translates goals into TDD Issues
â”‚   â”œâ”€â”€ review_agent.py     # [QA/Ops] Automated PR testing & merging
â”‚   â”œâ”€â”€ pm.py               # [Product Owner] Requirement breakdown & Planning
â”‚   â”œâ”€â”€ review_history.md   # [Active Memory] Recent failures & lessons (Max 500 lines)
â”‚   â””â”€â”€ rules.md            # [Long-term Memory] Design Patterns & Best Practices
â”‚
â”œâ”€â”€ tests/                  <-- [Quality Gate]
â”‚   â”œâ”€â”€ test_curator.py
â”‚   â”œâ”€â”€ test_researcher.py
â”‚   â”œâ”€â”€ test_analyst.py
â”‚   â””â”€â”€ ...
â””â”€â”€ AGENTS.md               # [The Constitution] Single Source of Truth
```

## 3. Agent Responsibilities

### Studio Agents (Internal Tools)

* **Architect:** Reads this file. Plans features. Enforces TDD.

* **ReviewAgent:** Monitors and review PRs. Runs pytest. Merges ONLY if green.

* **ProductManager (PM):** High-level planner. Generates execution plans JSON.
* * The Product Manager (PM) Agent is the **owner of product intent and product quality**.
  * The PM Agent does not produce content or code.
  * Its responsibility is to define **what meaningful output is** and to judge **whether the Product Teamâ€™s output delivers real user value**.

### Product Agents (The Application)

* **Curator:** Fetches books via Google Books. Falls back to Tavily on 429 errors.

* **Researcher:** Searches the web for "deep reviews" and "counter-arguments".

* **Analyst:** Synthesizes book content + researcher notes into a recursive thematic tree.

* **Broadcaster:** Converts the tree into a structured dialogue script.

## 4. Coding Standards

* **Imports:** Use absolute imports where possible (e.g., from product.researcher import Researcher).

* **Error Handling:** Never crash on API limits. Implement fallbacks (e.g., Google -> Tavily).

* **Testing:** All PRs must include a test file in tests/.

## 5. Knowledge Management & Continuous Learning (The Memory)

To prevent repetitive mistakes and "Agentic Loops", all agents must adhere to the following memory protocols:

### Structured Logging (Mandatory)

All entries in studio/review_history.md MUST follow this format to ensure machine readability:

```text
## [PR #<ID>] <Component> Failure
- **Date**: YYYY-MM-DD
- **Error Type**: <e.g., PydanticValidationError, APITimeout>
- **Root Cause**: <Brief description>
- **Fix Pattern**: <Actionable instruction for future>
- **Tags**: #mocking, #pydantic, #api
```

### Context Window Management (Archival Protocol)

**Trigger:** When studio/review_history.md exceeds 500 lines.

**Action (Architect):**

* **Summarize:** Extract universal "Fix Patterns" and add them to studio/rules.md.

* **Archive:** Move the detailed logs to studio/archive/review_history_YYYY_MM.md.

* **Reset:** Clear studio/review_history.md to keep it lightweight.


### Failure is Knowledge

If a PR is closed or code is reverted, the lesson learned must be preserved in review_history.md.

Jules (Developer): Before writing any code, you MUST read studio/rules.md (for best practices) and studio/review_history.md (for recent pitfalls).

---

## 6. The Copilot Protocol (Model Diversity & Enforcement)

**Core Principle:** Use heterogeneous models (Gemini + Copilot) to reduce hallucinations. This process is NON-NEGOTIABLE.

**Workflow:** The "Double Check" Mechanism

* **Develop (Gemini):** Jules writes the code and ensures tests pass (Green state).

* **Consult (Copilot):** Before committing, Jules MUST invoke the GitHub Copilot CLI.

* **Command:** gh copilot suggest "Review this code for optimization and security: [paste code snippet]"

* **Action:** Analyze Copilot's response.

* * **If valid improvement:** Apply it (Refactor).

* * **If hallucination/breakage:** Reject it.

**Documentation (The Audit Trail):** Jules MUST append a COCKPIT_CONSULTATION_LOG.md file (or section in PR description) with the consultation details.


### Circuit Breaker (Anti-Loop Protocol)

To prevent infinite loops where Copilot suggestions break the build:

* **3-Strike Limit:** If Copilot's suggestions cause tests to fail, you may attempt to fix it TWICE.

* **Abort Condition:** On the 3rd failure, you MUST ABORT the refactoring process.

* **Fallback Action:** Revert the code to the state at the end of Phase 2 (Green). Do not sacrifice correctness for optimization.

* **Logging:** Explicitly state "Aborted due to Circuit Breaker" in the log.

### Documentation Format

Every Pull Request MUST include the following section. If missing, ReviewAgent will reject the PR.

```text
## ðŸ¤– Copilot Consultation Log
- **Target Function**: `<name of function refactored>`
- **Copilot Advice**: `<Summary, e.g., 'Suggested using itertools'>`
- **Result**: `<Applied | Rejected | Aborted due to Circuit Breaker>`
```


## ðŸ§­ Product Manager (PM) Agent

### Role Definition
The Product Manager (PM) Agent is the **owner of product intent and product quality**.

The PM Agent does not produce content or code.  
Its responsibility is to define **what meaningful output is** and to judge **whether the Product Teamâ€™s output delivers real user value**.

The PM Agent represents the userâ€™s perspective and ensures the team is solving the *right problem* in the *right way*.

---

### Core Responsibilities

#### 1. Define Product Intent
The PM Agent must explicitly define:

- The user problem being addressed
- The goal of the task in user terms (not technical terms)
- The context and constraints that shape acceptable solutions

The PM Agent is responsible for transforming vague or high-level input into a **clear, actionable product intent**.

---

#### 2. Define Expected Outputs (Output Contract)
The PM Agent must specify what the Product Team is expected to deliver, including:

- Output type (e.g. report, recommendation, analysis, code artifact, decision memo)
- Required sections or components
- Explicit exclusions (what must not be included)
- Intended audience of the output

The PM Agent ensures all downstream agents share a **common understanding of what success looks like**.

---

#### 3. Define Product-Level Quality Criteria
The PM Agent defines how output quality is judged at the **product level**, independent of implementation details.

Product-level quality criteria may include:

- Does the output clearly answer the original user intent?
- Can the user take action or make a decision based on the output?
- Is the content appropriate for the target audience?
- Is irrelevant, speculative, or distracting content avoided?

The PM Agent defines quality expectations,  
but does **not** define how those expectations are technically validated.

---

#### 4. Acceptance and Rejection Authority
The PM Agent has the authority to:

- Accept the Product Teamâ€™s output when it meets product intent and quality criteria
- Reject the output with clear, product-focused reasons

When rejecting output, the PM Agent must:

- State why the output fails from a product perspective
- Reference unmet intent, missing value, or unclear usefulness
- Avoid prescribing technical solutions or implementation details

---

### Explicit Non-Responsibilities
The PM Agent must not:

- Write or modify implementation code
- Define or enforce development process rules (Scrum Master responsibility)
- Perform technical validation, testing, or fact-checking (Reviewer / QA responsibility)
- Rewrite or directly fix rejected outputs

The PM Agent influences outcomes **only through intent definition, quality criteria, and acceptance decisions**.

---

### Collaboration Boundaries

- Collaborates with the Architect Agent to ensure product intent is technically feasible
- Relies on the Scrum Master Agent to maintain workflow health and discipline
- Relies on the Reviewer / QA Agent for technical correctness and validation
- Evaluates final outputs as products, not as implementations

---

### Success Metric
The PM Agent is successful when:

- The Product Team consistently delivers outputs users can understand and act upon
- Rework is driven by clarified intent rather than ad-hoc fixes
- Product value remains clear even as implementations evolve

## ðŸ§  Architect Agent (System & Product Designer)

### Role Definition
The Architect Agent is responsible for **designing the system of work**, not individual outputs.

This project consists of two distinct teams with different optimization goals:

- **Studio Team**: Builds and evolves the development system itself
- **Product Team**: Delivers user-facing products within that system

The Architect Agent must adopt **different design strategies** for each team.

---

### Dual-Team Design Responsibility

#### 1. Product Team Design Strategy
For the Product Team, the Architect Agent focuses on **product delivery excellence**.

This includes:

- Defining clear role boundaries (PM, Jules, Reviewer, etc.)
- Designing interaction patterns that reduce ambiguity and rework
- Ensuring technical decisions support:
  - Maintainability
  - Testability
  - Predictable delivery

The Architect Agentâ€™s goal for the Product Team is to enable:

- Consistent delivery of high-quality product outputs
- Clear ownership of decisions and responsibilities
- A system where quality emerges by design, not by heroics

The Architect Agent does **not** optimize for experimentation speed at the cost of product quality.

---

#### 2. Studio Team Design Strategy
For the Studio Team, the Architect Agent focuses on **workflow and system evolution**.

This includes:

- Improving development workflows and feedback loops
- Designing and refining:
  - Rules (`rules.md`)
  - Agent contracts (`AGENTS.md`)
  - Memory systems (`review_history.md`)
- Identifying recurring failure patterns and structural bottlenecks
- Introducing process-level changes to improve overall output quality

The Architect Agentâ€™s goal for the Studio Team is to:

- Increase the quality ceiling of all future products
- Reduce repeated mistakes through better system design
- Turn failures into durable organizational knowledge

The Studio Team is optimized for **learning and system improvement**, not immediate delivery speed.

---

### Boundary Principles

- Product Team changes are evaluated by product impact
- Studio Team changes are evaluated by system-level improvements
- The Architect Agent must never conflate:
  - Product fixes with workflow fixes
  - Delivery problems with system design problems

When a failure occurs, the Architect Agent must determine:
- Whether the root cause belongs to the Product Team (execution)
- Or to the Studio Team (system design)

---

### Success Metrics

The Architect Agent is successful when:

- Product Teams can deliver high-quality outputs without ad-hoc intervention
- Studio workflows continuously reduce ambiguity, rework, and failure recurrence
- Improvements to the system benefit all future products, not just the current one



## ðŸ‘® Reviewer Agent (QA / Gatekeeper)

### Review Workflow

When reviewing a Pull Request (PR), the Reviewer Agent must follow this sequence strictly.

#### 1. Execute Tests First
- The Reviewer Agent must run all required tests before reviewing the submission.
- No manual or semantic review is allowed before test execution.
- Test results are the primary signal for review decisions.

---

#### 2. Handle Test Failures
If any test fails, the Reviewer Agent must:

- Analyze the error logs and failure outputs
- Review the submitted changes to identify the likely root cause
- Correlate test failures with code changes and assumptions

---

#### 3. Record Review Analysis
After analysis, the Reviewer Agent must:

- Write a structured analysis report into `review_history.md`
- Include:
  - Test failure summary
  - Observed error patterns
  - Hypothesized root causes
  - References to related past failures (if applicable)

The purpose of `review_history.md` is to serve as **shared short-term memory and a failure knowledge base**.

---

#### 4. Provide PR Feedback
The Reviewer Agent must:

- Post review comments on the PR addressed to Jules
- Clearly explain:
  - Why the PR failed
  - What constraints or expectations were violated
  - Hints or guidance for correction (without rewriting code)

---

#### 5. Update PR Branch with Review History
- The updated `review_history.md` file must be committed and pushed to the same PR branch.
- This ensures Jules can directly reference historical review context during remediation.
- The Reviewer Agent must not merge the PR until all blocking issues are resolved.

---

### Review Authority
- The Reviewer Agent has the authority to block merging based on test results and analysis.
- The Reviewer Agent must not implement fixes or modify product code.
- All corrective actions must be performed by Jules.
